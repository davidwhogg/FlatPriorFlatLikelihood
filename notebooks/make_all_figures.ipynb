{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0b/kkcrIbWI0AvyNmJUlt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidwhogg/FlatPriorFlatLikelihood/blob/main/notebooks/To_Gaby_From_Hogg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# For Gaby: flat LF, flat priors, and yet peaked posterior\n",
        "\n",
        "## Authors:\n",
        "- **David W. Hogg** (NYU) (MPIA)\n",
        "\n",
        "## Projects:\n",
        "- Show that even in the simplest situation: Everything linear, everything Gaussian, and flat priors, the Bayesian posterior is peaked when the likelihood function is not.\n",
        "  - That is, even integrating a flat LF over a flat prior can give you a spurious peak. It's sweet! The fundamental reason is that in more than a few dimensions, any misalignment between the model degeneracy and the box edges will give you structure.\n",
        "\n",
        "## Bugs / To-do items:\n",
        "- Show that as the truth (`CENTER`) moves, the peak in the LF moves accordingly.\n",
        "- Explore the effect of dimensionality of the space.\n",
        "- Explore the effect of the dimensionality of the degeneracy.\n",
        "- Show plots that are aligned with the degeneracy.\n",
        "- Show that the problem is easy to diagnose by changing the limits of the prior.\n",
        "- Switch to a latin hypercube, maybe?\n"
      ],
      "metadata": {
        "id": "8kUwNyqAi3Nm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyRSIiW6i2Yh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pylab as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters / choices\n",
        "P = 6 # dimensionality of the space\n",
        "Q = 2 # dimensionality of the null space (exact degeneracy space)\n",
        "M = 12 # number of samplings to do\n",
        "N = 2 ** (13 + P // 3) # number of samples per sampling\n",
        "print(P, Q, M, N)"
      ],
      "metadata": {
        "id": "HGU2XGwHjiFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make some random numbers to define our Universe\n",
        "rng = np.random.default_rng(17)\n",
        "CENTER = 10. * rng.uniform(size=P)\n",
        "VECS = rng.normal(size=(P, P))"
      ],
      "metadata": {
        "id": "JvZ_hgADjGzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now orthogonalize to make a randomly oriented orthonormal coordinate system\n",
        "UNITVECS = np.zeros((P, P))\n",
        "for i in range(P):\n",
        "    veci = 1. * VECS[i]\n",
        "    for j in range(i):\n",
        "        uvecj = UNITVECS[j]\n",
        "        veci -= (veci @ uvecj) * uvecj\n",
        "    UNITVECS[i] = veci / np.linalg.norm(veci)"
      ],
      "metadata": {
        "id": "kaHjxMO-mTYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a LLF with an exact M-dimensional degeneracy\n",
        "def log_likelihood(points):\n",
        "    \"\"\"\n",
        "    ## Bugs:\n",
        "    - Only can take lists of points, not a single point.\n",
        "    - Relies on global variables.\n",
        "    \"\"\"\n",
        "    deltas = (UNITVECS[Q:] @ (points.T - CENTER[:, None])).T\n",
        "    return 10.0 - 0.5 * np.sum(deltas * deltas, axis=1)"
      ],
      "metadata": {
        "id": "JywiJ2tkkSNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a plot center that is near to a high-likelihood point, but integer\n",
        "plot_center = np.round(CENTER + np.random.normal(size=CENTER.shape))\n",
        "axis_labels = [f\"\\\\theta_{{{i+1}}}\" for i in range(P)]\n",
        "print(plot_center, axis_labels)"
      ],
      "metadata": {
        "id": "G9QDUW9BnJF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make MN samplings in a cube\n",
        "halfsize = 5.0\n",
        "points = 2. * halfsize * rng.uniform(size=(M * N, P)) - halfsize + plot_center[None, :]\n",
        "llfs = log_likelihood(points)\n",
        "print(points.shape, llfs.shape)"
      ],
      "metadata": {
        "id": "FuyHULzFnk4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FIGSIZE = 3. # units?\n",
        "nx = np.ceil(np.sqrt(P)).astype(int)\n",
        "ny = np.ceil(P / nx).astype(int)\n",
        "fig, axs = plt.subplots(ny, nx, figsize=(FIGSIZE * nx, FIGSIZE * ny), sharey=True)\n",
        "axs = axs.flatten()\n",
        "for i in range(P):\n",
        "    ax = axs[i]\n",
        "    # ax.axvline(CENTER[i], lw=1, color=\"k\", alpha=0.5)\n",
        "    foo, bar = np.histogram(points[:, i], weights=np.exp(llfs[:]), density=True)\n",
        "    xlabel = f\"$p({axis_labels[i]}|Y)$\"\n",
        "    ax.stairs(foo, bar, color=\"k\", alpha=1.0, fill=False, label=xlabel)\n",
        "    for m in range(M):\n",
        "        foo, bar = np.histogram(points[m::M, i], weights=np.exp(llfs[m::M]), density=True)\n",
        "        ax.stairs(foo, bar, color=\"k\", alpha=0.25, fill=False)\n",
        "    # ax.legend(loc=8)\n",
        "    ax.text(0.05, 0.95, f\"${axis_labels[i]}$\", transform=ax.transAxes,\n",
        "            ha=\"left\", va=\"top\")\n",
        "    ax.set_xlim(plot_center[i] - halfsize, plot_center[i] + halfsize)\n",
        "for j in range(i+1, len(axs)):\n",
        "    axs[j].set_visible(False)"
      ],
      "metadata": {
        "id": "3Ghp7iDTq9KZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert False"
      ],
      "metadata": {
        "id": "x88icXgnnkAl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Nplot = 2 ** 11\n",
        "vmax = np.max(llfs)\n",
        "vmin = vmax - 5.0\n",
        "fig, axs = plt.subplots(P-1, P-1, figsize=(FIGSIZE * (P - 1), FIGSIZE * (P - 1)))\n",
        "print(axs.shape)\n",
        "for i in range(1, P):\n",
        "    for j in range(i):\n",
        "        ax = axs[i - 1, j]\n",
        "        ax.scatter(points[:Nplot, j], points[:Nplot, i], s=4, c=llfs[:Nplot],\n",
        "                   vmin=vmin, vmax=vmax, cmap=\"viridis_r\", alpha=0.75)\n",
        "        if i == (P - 1): ax.set_xlabel(axis_labels[j])\n",
        "        if j == 0: ax.set_ylabel(axis_labels[i])\n",
        "    for j in range(i, P - 1):\n",
        "        axs[i - 1, j].set_visible(False)"
      ],
      "metadata": {
        "id": "fidul5uyo5UB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lj6DAMy-qBMF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}